{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/tanmayeegupte/Documents/Bankruptcy_Project/Company-Bankruptcy-Prediction/Data.csv')\n",
    "X = dataset.iloc[:, 1:].values\n",
    "y = dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x: (6819, 95)\n",
      "shape of y: (6819,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of x: {}\\nshape of y: {}\".format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining dataset class\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.tensor(x,dtype=torch.float32)\n",
    "        self.y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.length = self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5455, 95), (5455,), (1364, 95), (1364,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = dataset(X,y)\n",
    "X.shape,y.shape, X_test.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader\n",
    "trainloader = DataLoader(trainset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the network\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,input_shape):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape,64)\n",
    "        self.fc2 = nn.Linear(64,1)\n",
    "#        self.fc3 = nn.Linear(64,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "#        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "model = Net(input_shape=X.shape[1])\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\tloss : 0.32065531611442566\t accuracy : 0.968102658111824\n",
      "epoch 50\tloss : 0.009221795946359634\t accuracy : 0.970852428964253\n",
      "epoch 100\tloss : 0.006493484601378441\t accuracy : 0.9730522456461962\n",
      "epoch 150\tloss : 0.00590392854064703\t accuracy : 0.9739688359303391\n",
      "epoch 200\tloss : 0.005344007629901171\t accuracy : 0.9752520623281393\n",
      "epoch 250\tloss : 0.004646751563996077\t accuracy : 0.9761686526122824\n",
      "epoch 300\tloss : 0.004155813250690699\t accuracy : 0.9765352887259395\n",
      "epoch 350\tloss : 0.0037975122686475515\t accuracy : 0.9770852428964253\n",
      "epoch 400\tloss : 0.00345267029479146\t accuracy : 0.9778185151237397\n",
      "epoch 450\tloss : 0.00316617707721889\t accuracy : 0.9787351054078827\n",
      "epoch 500\tloss : 0.0027967102359980345\t accuracy : 0.9798350137488543\n",
      "epoch 550\tloss : 0.0025351110380142927\t accuracy : 0.9802016498625115\n",
      "epoch 600\tloss : 0.002356545301154256\t accuracy : 0.9811182401466545\n",
      "epoch 650\tloss : 0.0021625603549182415\t accuracy : 0.982218148487626\n",
      "epoch 700\tloss : 0.001961239380761981\t accuracy : 0.9838680109990834\n",
      "epoch 750\tloss : 0.0017996308160945773\t accuracy : 0.9844179651695693\n",
      "epoch 800\tloss : 0.001672885729931295\t accuracy : 0.9853345554537122\n",
      "epoch 850\tloss : 0.0015695818001404405\t accuracy : 0.9864344637946838\n",
      "epoch 900\tloss : 0.0014987594913691282\t accuracy : 0.9869844179651696\n",
      "epoch 950\tloss : 0.0014394925674423575\t accuracy : 0.9882676443629698\n"
     ]
    }
   ],
   "source": [
    "#forward loop\n",
    "losses = []\n",
    "accur = []\n",
    "for i in range(epochs):\n",
    "    for j,(x_train,y_train) in enumerate(trainloader):\n",
    "    \n",
    "        #calculate output\n",
    "        output = model(x_train)\n",
    " \n",
    "        #calculate loss\n",
    "        loss = loss_fn(output,y_train.reshape(-1,1))\n",
    " \n",
    "        #accuracy\n",
    "        predicted = model(torch.tensor(X,dtype=torch.float32))\n",
    "        acc = (predicted.reshape(-1).detach().numpy().round() == y).mean()\n",
    "        #backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%50 == 0:\n",
    "        losses.append(loss)\n",
    "        accur.append(acc)\n",
    "        print(\"epoch {}\\tloss : {}\\t accuracy : {}\".format(i,loss,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1305   13]\n",
      " [  35   11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9648093841642229"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the model on test data\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "predicted1 = model(torch.tensor(X_test,dtype=torch.float32))\n",
    "y_pred1 = predicted1.reshape(-1).detach().numpy().round()\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
